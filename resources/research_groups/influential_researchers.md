# Influential Researchers and Research Groups

Key researchers and institutions working on bias mitigation and artifact reduction in NLP (2021-2025).

---

## Leading Researchers

### Yoav Goldberg ⭐⭐⭐⭐⭐
- **Affiliation**: Bar-Ilan University, AI2-Israel
- **Research Focus**: NLP, bias mitigation, neural network interpretability
- **Key Contributions**:
  - INLP (Null It Out) - ACL 2020
  - RLACE (Linear Adversarial Concept Erasure) - ICML 2022
  - Log-linear Guardedness - ACL 2023
- **GitHub**: https://github.com/yoavg (gist account)
- **Google Scholar**: https://scholar.google.com/citations?user=0rskDKgAAAAJ
- **Citations**: 20,000+
- **Notable Collaborators**: Shauli Ravfogel
- **Recent Work (2023-2024)**:
  - Concept erasure methods
  - Limitations of linear guardedness
  - Conformal nucleus sampling
- **Website**: https://u.cs.biu.ac.il/~yogo/

### Shauli Ravfogel ⭐⭐⭐⭐⭐
- **Affiliation**: Bar-Ilan University (PhD with Yoav Goldberg)
- **Research Focus**: Bias removal, concept erasure, neural representations
- **Key Contributions**:
  - INLP - ACL 2020 (800+ citations)
  - RLACE - ICML 2022 (500+ citations)
  - LEACE - NeurIPS 2023 (with EleutherAI)
  - Adversarial Concept Erasure in Kernel Space
- **GitHub**: https://github.com/shauli-ravfogel
- **Website**: https://shauli-ravfogel.netlify.app/
- **Active Repositories**:
  - nullspace_projection (INLP)
  - rlace-icml (RLACE)
  - adv-kernel-removal
  - linear-guardedness (ACL 2023)
- **Awards**: Prestigious fellowship (Bar-Ilan University)
- **Recent**: Stanford NLP Seminar speaker (2024)

### Swabha Swayamdipta ⭐⭐⭐⭐⭐
- **Affiliation**: University of Southern California (USC)
- **Research Focus**: Dataset quality, training dynamics, data-centric AI
- **Key Contributions**:
  - Dataset Cartography - EMNLP 2020
  - Data quality analysis
  - Training dynamics for bias detection
- **Google Scholar**: https://scholar.google.com/citations?user=3uTVQt0AAAAJ
- **Citations**: 10,000+
- **Key Paper**: Dataset Cartography (1000+ citations)
- **Impact**: Widely adopted method for identifying easy/hard/ambiguous examples
- **Recent Applications (2023-2024)**:
  - Hard example mining
  - Bias mitigation through selective training
  - GPT-3 for challenging reasoning patterns

### Christopher Clark ⭐⭐⭐⭐
- **Affiliation**: Google (formerly University of Washington, Allen Institute for AI)
- **Research Focus**: Out-of-domain generalization, preventing shallow heuristics
- **Key Contributions**:
  - Ensemble debiasing methods
  - Product of Experts for bias mitigation
  - "Don't Take the Easy Way Out" paper
- **GitHub**: https://github.com/chrisc36
- **Google Scholar**: https://scholar.google.com/citations?user=CmzeVaEAAAAJ
- **Citations**: 22,000+
- **PhD**: University of Washington (with Luke Zettlemoyer)
- **Key Repository**: chrisc36/debias
- **Research Areas**: Out-of-domain generalization, multi-modal ML

### Robin Jia ⭐⭐⭐⭐⭐
- **Affiliation**: University of Southern California (USC)
- **Research Focus**: Adversarial robustness, model evaluation, uncertainty
- **Key Contributions**:
  - Adversarial SQuAD - EMNLP 2017 (1000+ citations)
  - Certified Robustness to Adversarial Word Substitutions - EMNLP 2019
  - Chain-of-Questions Training - EMNLP 2023
  - SCENE (Self-Labeled Counterfactuals) - EMNLP 2023
- **GitHub**: https://github.com/robinjia
- **Website**: https://robinjia.github.io/
- **Recent Work (2023-2024)**:
  - Benchmarking long-tail generalization (EACL Findings 2023)
  - LLM calibration (EMNLP Findings 2023)
  - Data watermarking for LLMs (ACL Findings 2024)
- **Teaching**: CSCI 699: Robustness and Generalization in NLP
- **Workshops**: Co-organized Dynamic Adversarial Data Collection (NAACL 2022)

### Emily M. Bender ⭐⭐⭐⭐⭐
- **Affiliation**: University of Washington
- **Research Focus**: Ethics in NLP, bias in language technology, language documentation
- **Key Contributions**:
  - Data Statements for NLP
  - Ethics in NLP frameworks
  - Critical analysis of LLM risks
  - "Bender Rule": Always name languages in NLP research
- **Recent Work (2023-2024)**:
  - "Resisting Dehumanization in the Age of 'AI'" (2024)
  - "Ethics in Linguistics" (Annual Review, 2023)
  - "Data Statements: From Technical Concept to Community Practice" (ACM JRC, 2024)
- **Recognition**: TIME 100 Most Influential People in AI (2023)
- **Website**: https://faculty.washington.edu/ebender/
- **Impact**: Shaped policy discussions on AI bias and fairness
- **Key Argument**: "Automating bias" through insensitive NLP development

---

## Research Groups and Institutions

### Allen Institute for AI (AI2) ⭐⭐⭐⭐⭐
- **Location**: Seattle, WA
- **Website**: https://allenai.org/
- **Key Contributions**:
  - Dataset Cartography (allenai/cartography)
  - Persona-bias dataset (ICLR 2024)
  - CheckList collaborations
  - AllenNLP fairness module
- **GitHub**: https://github.com/allenai
- **Notable Researchers**: Swabha Swayamdipta, Yejin Choi, many others
- **Active Projects (2023-2024)**:
  - Persona bias in LLMs
  - Implicit reasoning biases
- **Status**: Highly active in fairness research

### McGill NLP Group ⭐⭐⭐⭐⭐
- **Location**: McGill University, Montreal
- **PI**: Siva Reddy
- **Key Contributions**:
  - bias-bench (ACL 2022)
  - Comprehensive debiasing evaluation
- **GitHub**: https://github.com/McGill-NLP
- **Website**: https://mcgill-nlp.github.io/
- **Notable Work**: Empirical Survey of Debiasing Techniques (ACL 2022)
- **Impact**: Standard benchmark for debiasing research

### UCLA NLP Group ⭐⭐⭐⭐
- **Location**: University of California, Los Angeles
- **GitHub**: https://github.com/uclanlp
- **Key Contributions**:
  - awesome-fairness-papers repository
  - Curated fairness research collection
- **Maintenance**: Actively updated through 2024
- **Impact**: Central resource for fairness in NLP literature

### Vector Institute ⭐⭐⭐⭐
- **Location**: Toronto, Canada
- **Website**: https://vectorinstitute.ai/
- **Key Contributions**:
  - Bias mitigation through unlearning (EMNLP 2024)
  - Machine unlearning methods
- **GitHub**: https://github.com/VectorInstitute
- **Recent Work**: Negation via Task Vectors (25.5% bias reduction)
- **Repository**: bias-mitigation-unlearning

### Microsoft Research ⭐⭐⭐⭐⭐
- **Key Contributors**: Marco Tulio Ribeiro, others
- **Key Contributions**:
  - CheckList (ACL 2020) - 1000+ citations
  - Behavioral testing framework
- **GitHub**: https://github.com/marcotcr/checklist
- **Impact**: Industry standard for model testing
- **Adoption**: Widely used in production systems

### IBM Research - Trusted AI ⭐⭐⭐⭐⭐
- **Website**: https://aif360.res.ibm.com/
- **Key Contributions**:
  - AIF360 (AI Fairness 360) toolkit
  - 70+ fairness metrics
  - 10+ mitigation algorithms
- **GitHub**: https://github.com/Trusted-AI/AIF360
- **Impact**: Industry-standard fairness toolkit
- **Stars**: 2000+
- **Maintenance**: Actively maintained through 2024

### Tsinghua University NLP Lab (THUNLP) ⭐⭐⭐⭐
- **Location**: Beijing, China
- **GitHub**: https://github.com/thunlp
- **Key Contributions**:
  - TAADpapers (Textual Adversarial Attack and Defense)
  - Comprehensive paper collections
- **Repository**: Must-read papers on adversarial NLP
- **Updates**: Very active through 2024
- **Stars**: 1000+

### EleutherAI ⭐⭐⭐⭐
- **Type**: Open-source AI research collective
- **GitHub**: https://github.com/EleutherAI
- **Key Contributions**:
  - LEACE (concept-erasure repository)
  - Open-source LLMs
  - Fairness research
- **Collaboration**: Works with academic researchers (e.g., LEACE with Ravfogel)
- **Status**: Very active in 2024

---

## Emerging Researchers (2023-2024)

### Focus Areas
- **LLM-specific debiasing**: Adapting methods to billion-parameter models
- **Multilingual fairness**: Cross-lingual bias transfer
- **Causal inference**: Using causality for bias mitigation
- **Open-set bias**: Generalizing beyond known categories

### Notable Names to Watch
- Zhijing Jin (CausalNLP)
- Nicholas Meade (McGill NLP, bias-bench)
- Angelina McMillan-Major (Data statements)

---

## Key Conferences and Workshops

### Major Venues (2024-2025)
1. **ACL** - Association for Computational Linguistics
2. **EMNLP** - Empirical Methods in NLP
3. **NAACL** - North American Chapter of ACL
4. **FAccT** - Fairness, Accountability, and Transparency
5. **ICLR** - International Conference on Learning Representations
6. **NeurIPS** - Neural Information Processing Systems

### Specialized Workshops
- **Gender Bias in NLP** (ACL 2024)
- **Ethics and Trust in Human-AI Collaboration** (IJCAI 2023)
- **Algorithmic Bias** (ECIR 2023, SIGIR 2024)
- **LLMs for Individuals, Groups, and Society** (WSDM 2024)
- **Dynamic Adversarial Data Collection** (NAACL 2022)

---

## Following the Field

### Mailing Lists and Communities
- **ACL Portal**: https://aclweb.org/
- **FAccT**: https://facctconference.org/
- **Papers with Code**: Track implementations

### Social Media
- Twitter/X: @swabhz (Swayamdipta), others share latest papers
- GitHub: Star key repositories for updates

### arXiv Categories
- cs.CL (Computation and Language)
- cs.LG (Machine Learning)
- cs.AI (Artificial Intelligence)
- cs.CY (Computers and Society)

---

## Collaboration Patterns

### Strong Collaborations
1. **Goldberg ↔ Ravfogel**: Concept erasure methods
2. **AI2 ↔ University of Washington**: Dataset quality, robustness
3. **McGill NLP ↔ Stanford**: Bias evaluation
4. **EleutherAI ↔ Academia**: Open-source debiasing tools

### Cross-Institutional Projects
- bias-bench (McGill + Stanford)
- LEACE (EleutherAI + Bar-Ilan)
- CheckList (Microsoft + UW)

---

## Research Funding and Support

### Major Funders
- NSF (National Science Foundation) - US
- NSERC (Natural Sciences and Engineering Research Council) - Canada
- ERC (European Research Council) - Europe
- Corporate labs (Google, Microsoft, IBM, Meta)

---

**Last Updated**: November 2025
**Note**: Citation counts and affiliations current as of late 2024/early 2025
